# ðŸ“‹ Mejoras Sugeridas para Rusty Bargain

Este documento contiene recomendaciones para mejorar el proyecto de predicciÃ³n de precios de vehÃ­culos.

---

## ðŸ”´ PROBLEMAS CRÃTICOS

### 1. Imports innecesarios
**UbicaciÃ³n:** LÃ­nea 108, 103

**Problema:**
- `f1_score` y `confusion_matrix` son para clasificaciÃ³n, no regresiÃ³n
- `preprocessing` genÃ©rico nunca se usa

**AcciÃ³n:**
```python
# Eliminar estas lÃ­neas:
from sklearn.metrics import mean_squared_error, r2_score, f1_score, confusion_matrix
from sklearn import preprocessing

# Reemplazar por:
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
```

**Prioridad:** â­â­â­ ALTA

---

### 2. Error en el modelo LightGBM
**UbicaciÃ³n:** LÃ­nea 576

**Problema:**
El tiempo de entrenamiento usa `t0` del modelo Random Forest, no de LightGBM.

**AcciÃ³n:**
```python
# Agregar ANTES de entrenar LightGBM (lÃ­nea 557):
t0 = time.time()
model_lgbm = LGBMRegressor(...)
```

**Prioridad:** â­â­â­ ALTA

---

### 3. Inconsistencia en datos de entrenamiento
**UbicaciÃ³n:** LÃ­neas 520-578

**Problema:**
- Linear Regression y Random Forest usan `X_train_lr` (train + valid)
- LightGBM usa solo `train_chars` y `valid_chars` separados
- Las comparaciones no son justas

**AcciÃ³n:**
Unificar el enfoque para todos los modelos o documentar claramente por quÃ© son diferentes.

**Prioridad:** â­â­â­ ALTA

---

## ðŸŸ¡ MEJORAS IMPORTANTES

### 4. Falta de documentaciÃ³n README
**Problema:**
No existe un archivo `README.md` que explique el proyecto.

**AcciÃ³n:**
Crear `README.md` con:
- DescripciÃ³n del proyecto
- InstalaciÃ³n de dependencias
- CÃ³mo ejecutar el notebook
- Resultados principales
- Estructura del proyecto

**Prioridad:** â­â­â­ ALTA

---

### 5. Falta de .gitignore
**Problema:**
Archivos innecesarios podrÃ­an subirse a Git.

**AcciÃ³n:**
Crear `.gitignore` con:
```
.venv/
.DS_Store
__pycache__/
*.pyc
.ipynb_checkpoints/
*.pkl
*.joblib
```

**Prioridad:** â­â­â­ ALTA

---

### 6. GestiÃ³n de outliers mejorable
**UbicaciÃ³n:** LÃ­neas 298-315, 361-381

**Problema:**
- CÃ³digo repetitivo
- LÃ­nea 362: Usa `car_data['power']` en lugar de `data_model['power']`

**AcciÃ³n:**
Crear funciÃ³n reutilizable:
```python
def remove_outliers(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    return df[(df[column] >= lower) & (df[column] <= upper)]

# Uso:
data_model_filtered = remove_outliers(car_data_filtered, 'price')
data_model_filtered = remove_outliers(data_model_filtered, 'power')
```

**Prioridad:** â­â­ MEDIA

---

### 7. Feature Engineering limitado
**UbicaciÃ³n:** LÃ­nea 324

**Problema:**
Eliminas columnas de fecha sin extraer informaciÃ³n Ãºtil.

**AcciÃ³n:**
Antes de eliminar, extraer features:
```python
# Convertir a datetime
car_data['date_created'] = pd.to_datetime(car_data['date_created'])
car_data['date_crawled'] = pd.to_datetime(car_data['date_crawled'])

# Crear nuevas features
car_data['vehicle_age'] = 2016 - car_data['registration_year']
car_data['days_since_posted'] = (car_data['date_crawled'] - car_data['date_created']).dt.days
```

**Prioridad:** â­â­ MEDIA

---

### 8. CodificaciÃ³n de variables categÃ³ricas
**UbicaciÃ³n:** LÃ­nea 432

**Problema:**
`OrdinalEncoder` para `model` y `brand` asume un orden que no existe.

**AcciÃ³n:**
Usar Target Encoding o Frequency Encoding:
```python
# Target Encoding (requiere category_encoders)
from category_encoders import TargetEncoder
te = TargetEncoder(cols=['model', 'brand'])
data_encoded = te.fit_transform(data_model_filtered[['model', 'brand']], 
                                 data_model_filtered['price'])

# O Frequency Encoding (mÃ¡s simple):
for col in ['model', 'brand']:
    freq = data_model_filtered[col].value_counts(normalize=True)
    data_model_filtered[f'{col}_freq'] = data_model_filtered[col].map(freq)
```

**Prioridad:** â­â­ MEDIA

---

### 9. Falta validaciÃ³n cruzada
**Problema:**
Solo un split Ãºnico puede dar resultados sesgados.

**AcciÃ³n:**
```python
from sklearn.model_selection import cross_val_score

# Para cada modelo:
cv_scores = cross_val_score(model, X, y, cv=5, 
                           scoring='neg_mean_squared_error')
rmse_cv = np.sqrt(-cv_scores.mean())
print(f"RMSE CV: {rmse_cv:.2f} (+/- {cv_scores.std():.2f})")
```

**Prioridad:** â­â­ MEDIA

---

### 10. MÃ©tricas adicionales
**Problema:**
Solo usas RMSE.

**AcciÃ³n:**
Agregar mÃ¡s mÃ©tricas:
```python
from sklearn.metrics import mean_absolute_error, r2_score

def evaluate_model(y_true, y_pred):
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    
    return {
        'RMSE': rmse,
        'MAE': mae,
        'RÂ²': r2,
        'MAPE': mape
    }
```

**Prioridad:** â­â­ MEDIA

---

## ðŸŸ¢ MEJORAS DE CÃ“DIGO Y ESTILO

### 11. Magic numbers
**UbicaciÃ³n:** LÃ­neas 335, 473

**Problema:**
Valores hardcodeados dificultan el mantenimiento.

**AcciÃ³n:**
Definir constantes al inicio:
```python
# ConfiguraciÃ³n
MIN_YEAR = 1950
MAX_YEAR = 2025
TEST_SIZE = 0.2
RANDOM_STATE = 12345
```

**Prioridad:** â­ BAJA

---

### 12. Falta logging de resultados
**Problema:**
Resultados solo se imprimen, no se almacenan estructuradamente.

**AcciÃ³n:**
```python
results = []
results.append({'Model': 'Linear Regression', **results_lr})
results.append({'Model': 'Random Forest', **results_rf})
results.append({'Model': 'LightGBM', **results_lgbm})

results_df = pd.DataFrame(results)
results_df.to_csv('model_results.csv', index=False)
print(results_df)
```

**Prioridad:** â­ BAJA

---

### 13. Escalado de features
**Problema:**
Importas `StandardScaler` pero nunca lo usas.

**AcciÃ³n:**
Probar escalado para Linear Regression:
```python
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_lr)
X_test_scaled = scaler.transform(X_test_lr)

model_lr.fit(X_train_scaled, y_train)
```

**Prioridad:** â­ BAJA

---

### 14. Guardado del modelo
**Problema:**
No guardas el mejor modelo.

**AcciÃ³n:**
```python
import joblib

# Guardar el mejor modelo
joblib.dump(model_lgbm, 'best_model_lgbm.pkl')

# Cargar despuÃ©s:
# model = joblib.load('best_model_lgbm.pkl')
```

**Prioridad:** â­ BAJA

---

## ðŸ“ˆ MEJORAS DE ANÃLISIS

### 15. Visualizaciones adicionales
**AcciÃ³n sugerida:**
```python
# Matriz de correlaciÃ³n
plt.figure(figsize=(12, 8))
sns.heatmap(data_model_filtered.corr(), annot=True, cmap='coolwarm')
plt.title('Matriz de CorrelaciÃ³n')
plt.show()

# Importancia de features (LightGBM)
import matplotlib.pyplot as plt
feature_importance = pd.DataFrame({
    'feature': X_train_lr.columns,
    'importance': model_lgbm.feature_importances_
}).sort_values('importance', ascending=False)

plt.figure(figsize=(10, 6))
plt.barh(feature_importance['feature'][:10], feature_importance['importance'][:10])
plt.xlabel('Importancia')
plt.title('Top 10 Features MÃ¡s Importantes')
plt.show()
```

**Prioridad:** â­ BAJA

---

### 16. AnÃ¡lisis de errores
**AcciÃ³n sugerida:**
```python
# AnÃ¡lisis de residuos
residuals = y_test - test_preds_lgbm

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.scatter(test_preds_lgbm, residuals, alpha=0.5)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('Predicciones')
plt.ylabel('Residuos')
plt.title('GrÃ¡fico de Residuos')

plt.subplot(1, 2, 2)
plt.hist(residuals, bins=50)
plt.xlabel('Residuos')
plt.title('DistribuciÃ³n de Residuos')
plt.show()

# AnÃ¡lisis por rango de precio
price_ranges = pd.cut(y_test, bins=5)
error_by_range = pd.DataFrame({
    'range': price_ranges,
    'error': np.abs(y_test - test_preds_lgbm)
}).groupby('range')['error'].mean()
print(error_by_range)
```

**Prioridad:** â­ BAJA

---

### 17. Velocidad de predicciÃ³n
**AcciÃ³n sugerida:**
```python
import time

# Medir tiempo de predicciÃ³n
n_predictions = 1000
t0 = time.time()
for _ in range(n_predictions):
    _ = model_lgbm.predict(X_test_lr[:1])
prediction_time = (time.time() - t0) / n_predictions

print(f"Tiempo promedio de predicciÃ³n: {prediction_time*1000:.2f}ms")
```

**Prioridad:** â­ BAJA

---

## âœ… LO QUE ESTÃ BIEN

- âœ… Buena estructura del notebook con markdown explicativo
- âœ… AnÃ¡lisis exploratorio detallado
- âœ… ComparaciÃ³n de mÃºltiples modelos
- âœ… Uso de GridSearchCV para Random Forest
- âœ… Early stopping en LightGBM
- âœ… Conclusiones claras al final

---

## ðŸ“Š RESUMEN DE PRIORIDADES

### â­â­â­ ALTA (Hacer primero)
1. Corregir bug del `t0` en LightGBM
2. Eliminar imports innecesarios
3. Unificar datos de entrenamiento
4. Crear `README.md`
5. Crear `.gitignore`

### â­â­ MEDIA (Hacer despuÃ©s)
6. Refactorizar eliminaciÃ³n de outliers
7. Agregar feature engineering de fechas
8. Mejorar encoding de variables categÃ³ricas
9. Implementar validaciÃ³n cruzada
10. Agregar mÃ¡s mÃ©tricas

### â­ BAJA (Opcional)
11. Definir constantes para magic numbers
12. Crear DataFrame de resultados
13. Probar escalado de features
14. Guardar modelo final
15. Agregar visualizaciones adicionales
16. AnÃ¡lisis de errores
17. Medir velocidad de predicciÃ³n

---

**Fecha de creaciÃ³n:** 2025-11-19
**VersiÃ³n:** 1.0
