{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUSTY BARGAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rusty Bargain es un servicio de venta de coches de segunda mano que está desarrollando una app para atraer a nuevos clientes. \n",
    "\n",
    "Gracias a esa app, puedes averiguar rápidamente el valor de mercado de tu coche. Tienes acceso al historial, especificaciones técnicas, versiones de equipamiento y precios.\n",
    "\n",
    "A Rusty Bargain le interesa:\n",
    "\n",
    "* La calidad de la predicción\n",
    "* La velocidad de la predicción\n",
    "* El tiempo requerido para el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear un modelo que determine el valor de mercado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consideraciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este proyecto consideraré:\n",
    "\n",
    "1. Features:\n",
    "\n",
    "- DateCrawled — fecha en la que se descargó el perfil de la base de datos\n",
    "- VehicleType — tipo de carrocería del vehículo\n",
    "- RegistrationYear — año de matriculación del vehículo\n",
    "- Gearbox — tipo de caja de cambios\n",
    "- Power — potencia (CV)\n",
    "- Model — modelo del vehículo\n",
    "- Mileage — kilometraje (medido en km de acuerdo con las especificidades regionales del conjunto de datos)\n",
    "- RegistrationMonth — mes de matriculación del vehículo\n",
    "- FuelType — tipo de combustible\n",
    "- Brand — marca del vehículo\n",
    "- NotRepaired — vehículo con o sin reparación\n",
    "- DateCreated — fecha de creación del perfil\n",
    "- NumberOfPictures — número de fotos del vehículo\n",
    "- PostalCode — código postal del propietario del perfil (usuario)\n",
    "- LastSeen — fecha de la última vez que el usuario estuvo activo\n",
    "\n",
    "\n",
    "2. Target\n",
    "\n",
    "- Price — precio (en euros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos y librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargaré todas las librerías que necesito.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from lightgbm.callback import early_stopping, log_evaluation\n",
    "import math\n",
    "import time\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/brisna/github_projects/tripleten/rusty_bargain/car_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cargaré los datos del nuevo dataset.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m car_data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/Users/brisna/github_projects/tripleten/rusty_bargain/car_data.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github_projects/repositorios/rusty_bargain/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github_projects/repositorios/rusty_bargain/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github_projects/repositorios/rusty_bargain/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github_projects/repositorios/rusty_bargain/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github_projects/repositorios/rusty_bargain/.venv/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/brisna/github_projects/tripleten/rusty_bargain/car_data.csv'"
     ]
    }
   ],
   "source": [
    "# Cargaré los datos del nuevo dataset.\n",
    "car_data = pd.read_csv('car_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veré la información general de mi dataframe.\n",
    "car_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisaré si hay datos nulos.\n",
    "car_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de revisar la información puedo observar que hay algunas variables que requieren atención:\n",
    "- Cambiaré los NaN de VehicleType, Gearbox, Model, Fueltype y NotRepaired por \"Desconocido\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiaré los NaN de VehicleType, Gearbox, Model, Fueltype y NotRepaired por \"Desconocido\".\n",
    "unknown_columns = [\"VehicleType\", \"Gearbox\", \"Model\", \"FuelType\", \"NotRepaired\"]\n",
    "car_data[unknown_columns] = car_data[unknown_columns].fillna(\"Desconocido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le daré formato a los encabezados para que queden uniformes.\n",
    "new_col_names = []\n",
    "for old_name in car_data.columns:\n",
    "    name_stripped = old_name.strip()\n",
    "    name_lowered = re.sub(r'(?<!^)(?=[A-Z])', '_', name_stripped).lower()\n",
    "    name_no_spaces = name_lowered.replace(\" \", \"_\")\n",
    "    new_col_names.append(name_no_spaces)\n",
    "\n",
    "car_data.columns = new_col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisaré cómo quedaron los encabezados.\n",
    "car_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volveré a revisar mi DataFrame. \n",
    "car_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observaré las estadísticas descriptivas de los datos.\n",
    "car_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según la descripción de los datos, puedo observar que:\n",
    "1. Hay 354,107 registros.\n",
    "2. Se capturaron datos del 5 de marzo al 7 de abril de 2016.\n",
    "3. El precio promedio es de $4,416.43 siendo 0 el precio más bajo y $20,000 el más alto registrado (revisaré esto más adelante).\n",
    "4. La desviación estándar es de $4,514.34 lo que indica una alta variabilidad en los precios.\n",
    "5. El año promedio de registro es 2004. Sin embargo, el año más bajo registrado es 1000 el más alto es 9999 por lo que revisaré también estos datos a detalle.\n",
    "6. La potencia promedio es de 110.09 siendo 0 la potencia mínima y 20,000 la máxima lo que me indica que podría haber errores en los datos.\n",
    "7. El kilometraje promedio es de 128,211.81km. El kilometraje más bajo es de 5,000km y el más alto es de 150,000km. La desviación estándar es de 37,906.59, lo que indica que los datos están muy dispersos.\n",
    "8.  El mes promedio de registro es de 5.71, lo que indica que la mayoría de los vehículos se registraron entre mayo y junio. El mes mínimo registrado es 0 lo cual podría indicar que el mes de registro es desconocido. La desviación estándar es 3.73, lo que indica una distribución normal de los datos.\n",
    "9. La fecha promedio de creación es el 20 de marzo de 2016 teniendo un periodo de tiempo de creación del 10 de marzo de 2014 al 7 de abril de 2016.\n",
    "10.  Observo que la columna number_of_pictures contiene solo ceros como valor por lo que podría eliminarla.\n",
    "11.  La columna postal_code tiene un rango que va del CP 1067 al 99998 lo que podría indicar que los autos pertenecen a diferentes regiones del país."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis exploratorio de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_data = car_data[car_data['price'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisaré los datos atípicos relacionados con el precio sin considerar el precio cero (0).\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(x=car_data['price'])\n",
    "plt.title('Distribución de Precios de los Autos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcularé el Q1 (percentil 25) y Q3 (percentil 75)\n",
    "Q1 = car_data['price'].quantile(0.25)\n",
    "Q3 = car_data['price'].quantile(0.75)\n",
    "\n",
    "# Calcularé el IQR\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filtraré los datos límites\n",
    "car_data_filtered = car_data[(car_data['price'] >= lower_bound) & (car_data['price'] <= upper_bound)]\n",
    "\n",
    "# Haré un boxplot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(x=car_data_filtered['price'], showfliers=False)\n",
    "plt.title('Distribución de Precios sin Valores Atípicos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitaré las variables de poco valor previo a la realización de mi modelo.\n",
    "data_model = car_data_filtered.drop(['postal_code', 'last_seen', 'date_created', 'date_crawled', 'number_of_pictures', 'registration_month'], axis=1)\n",
    "data_model.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtraré solo carros entre 1950 y 2025\n",
    "data_model = data_model[(data_model['registration_year'] >= 1950) & (data_model['registration_year'] <= 2025)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veré la cantidad de autos que hay por año de registro.\n",
    "registration_year_count = data_model['registration_year'].value_counts().sort_index()\n",
    "plt.figure()\n",
    "plt.bar(registration_year_count.index, registration_year_count.values)\n",
    "plt.xlabel('Año de registro')\n",
    "plt.ylabel('Cantidad de autos')\n",
    "plt.title('Autos registrados por año')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisaré los datos atípicos relacionados con el power sin considerar el cero (0).\n",
    "data_model = data_model[car_data['power'] > 0]\n",
    "\n",
    "# Calcularé el Q1 (percentil 25) y Q3 (percentil 75)\n",
    "Q1 = data_model['power'].quantile(0.25)\n",
    "Q3 = data_model['power'].quantile(0.75)\n",
    "\n",
    "# Calcularé el IQR\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
    "\n",
    "# Filtraré los datos límites\n",
    "data_model_filtered = data_model[(data_model['power'] >= lower) & (data_model['power'] <= upper)].copy()\n",
    "\n",
    "# Haré un boxplot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(x=data_model_filtered['power'], showfliers=False)\n",
    "plt.title('Distribución de Power sin Valores Atípicos')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model_filtered.reset_index(inplace=True)\n",
    "data_model_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificaré si tengo datos duplicados.\n",
    "data_model_filtered[data_model_filtered.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendré las variables categóricas para codificarlas.\n",
    "categorical_chars = list(data_model_filtered.dtypes[data_model_filtered.dtypes == 'object'].index)\n",
    "categorical_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for char in categorical_chars:\n",
    "    print(data_model_filtered[char].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haré una codificación ordinal para model y brand.\n",
    "data_model_filtered[['model', 'brand']] = OrdinalEncoder().fit_transform(data_model_filtered[['model', 'brand']])\n",
    "data_model_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ohe = pd.get_dummies(data_model_filtered, drop_first=True)\n",
    "data_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HALLAZGOS Y ACCIONES:\n",
    "\n",
    "* El dataset tenía varias columnas con valores faltantes y outliers que podrían sesgar los modelos. Después de imputar valores nulos y filtrar outliers en RegistrationYear, Power y Mileage, los datos quedaron más homogéneos.\n",
    "\n",
    "* Transformé las variables de fecha para extraer características (mes, año, etc.), lo que puede enriquecer los modelos basados en “edad” del anuncio o del vehículo.\n",
    "\n",
    "* No encontré valores duplicados sospechosos en el dataset, y la columna NumberOfPictures estaba en 0, por lo que decidí descartarla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiré mis metricas para el modelo.\n",
    "train_valid, test = train_test_split(data_ohe, test_size=0.2, random_state=12345)\n",
    "train, valid = train_test_split(train_valid, test_size=0.25,random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregaré el RMSE para evaluar la precisión de mi modelo.\n",
    "def rmse(prediction, real_value):\n",
    "    return math.sqrt(mean_squared_error(prediction,real_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparo mis datos para entrenar mi modelo.\n",
    "train_chars = train.drop('price', axis=1)\n",
    "valid_chars = valid.drop('price', axis=1)\n",
    "test_chars  = test.drop('price', axis=1)\n",
    "\n",
    "train_target = train['price']\n",
    "valid_target = valid['price']\n",
    "test_target  = test['price']\n",
    "\n",
    "print(\"train_chars:\", train_chars.shape, \"train_target:\", train_target.shape)\n",
    "print(\"valid_chars:\", valid_chars.shape, \"valid_target:\", valid_target.shape)\n",
    "\n",
    "# Entrenamiento y prueba combinando train y valid\n",
    "X_train_lr = pd.concat([train_chars, valid_chars])\n",
    "y_train = pd.concat([train_target, valid_target])\n",
    "\n",
    "X_test_lr = test_chars\n",
    "y_test = test_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haré un modelo de Regresión Lineal\n",
    "model_lr = LinearRegression()\n",
    "t0 = time.time()\n",
    "model_lr.fit(X_train_lr, y_train)\n",
    "train_preds_lr = model_lr.predict(X_train_lr)\n",
    "test_preds_lr = model_lr.predict(X_test_lr)\n",
    "results_lr = {'train_rmse': rmse(y_train, train_preds_lr), 'test_rmse': rmse(y_test, test_preds_lr), 'train_time': time.time() - t0}\n",
    "print(f\"Linear Regression -> Train RMSE: {results_lr['train_rmse']:.2f}, Test RMSE: {results_lr['test_rmse']:.2f}, Time: {results_lr['train_time']:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haré un modelo de Random Forest\n",
    "param_grid_rf = {'n_estimators': [100, 200], 'max_depth': [None, 10], 'min_samples_split': [2, 5]}\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "gs_rf = GridSearchCV(rf, param_grid_rf, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "\n",
    "t0 = time.time()\n",
    "gs_rf.fit(X_train_lr, y_train)\n",
    "model_rf = gs_rf.best_estimator_\n",
    "train_preds_rf = model_rf.predict(X_train_lr)\n",
    "test_preds_rf = model_rf.predict(X_test_lr)\n",
    "results_rf = {'best_params': gs_rf.best_params_, 'train_rmse': rmse(y_train, train_preds_rf), 'test_rmse': rmse(y_test, test_preds_rf), 'train_time': time.time() - t0}\n",
    "print(f\"Random Forest -> Params: {results_rf['best_params']}, Train RMSE: {results_rf['train_rmse']:.2f}, Test RMSE: {results_rf['test_rmse']:.2f}, Time: {results_rf['train_time']:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intentaré hacer un modelo de LightGBM.\n",
    "model_lgbm = LGBMRegressor(\n",
    "    n_estimators=1000,\n",
    "    metric='rmse',\n",
    "    verbose=-1\n",
    ")\n",
    "model_lgbm.fit(\n",
    "    train_chars, train_target,\n",
    "    eval_set=[(valid_chars, valid_target)],\n",
    "    eval_metric='rmse',\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=50),\n",
    "        log_evaluation(period=50)\n",
    "    ]\n",
    ")\n",
    "train_preds_lgbm = model_lgbm.predict(X_train_lr)\n",
    "test_preds_lgbm = model_lgbm.predict(X_test_lr)\n",
    "results_lgbm = {\n",
    "    'train_rmse': rmse(y_train, train_preds_lgbm),\n",
    "    'test_rmse': rmse(y_test, test_preds_lgbm),\n",
    "    'train_time': time.time() - t0\n",
    "}\n",
    "print(f\"LightGBM -> Train RMSE: {results_lgbm['train_rmse']:.2f}, Test RMSE: {results_lgbm['test_rmse']:.2f}, Time: {results_lgbm['train_time']:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones después de entrenar los modelos:\n",
    "\n",
    "* La Regresión Lineal es muy rápida, pero su calidad (RMSE) es la más baja.\n",
    "\n",
    "* El modelo de Random Forest mejora mucho el RMSE, pero el tiempo de entrenamiento es moderado.\n",
    "\n",
    "* LightGBM logra el mejor equilibrio entre calidad y velocidad (RMSE más bajo y entrenamiento más rápido que XGBoost o RF con muchos árboles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recomiendo usar LightGBM en producción ya que ofrece predicciones rápidas y de buena calidad aunque si el objetivo es maximizar la precisión y el tiempo de entrenamiento no es crítico, es buena idea también usar Random Forest con los parámetros óptimos encontrados.\n",
    "\n",
    "La Regresión Lineal será una buena opción solo como referencia rápida cada vez que se modifiquen características o se añadan nuevas variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}